{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from\n",
    "https://cloud.culture.tw/frontsite/trans/SearchShowAction.do?method=doFindTypeJOpenApi&category=all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step1. Load all data\n",
    "# Opening JSON file\n",
    "f_all = open('all_activities.json')\n",
    "\n",
    "# returns JSON object as \n",
    "# a dictionary, data, and a DataFrame, df\n",
    "data_all = json.load(f_all)\n",
    "df_all = pd.json_normalize(data_all)\n",
    "\n",
    "\n",
    "# Closing file\n",
    "f_all.close()\n",
    "\n",
    "# add a new column to mention the dataset it is from\n",
    "# df_all['dataset'] = pd.Series([0]).repeat(df_all.shape[0]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of original dataframe: (1450, 21)\n",
      "version                   0\n",
      "UID                       0\n",
      "title                     0\n",
      "category                 22\n",
      "showInfo                  0\n",
      "showUnit                  0\n",
      "discountInfo              0\n",
      "descriptionFilterHtml     0\n",
      "imageUrl                  0\n",
      "masterUnit                0\n",
      "subUnit                   0\n",
      "supportUnit               0\n",
      "otherUnit                 0\n",
      "webSales                  0\n",
      "sourceWebPromote          0\n",
      "comment                   0\n",
      "editModifyDate            0\n",
      "sourceWebName             0\n",
      "startDate                 0\n",
      "endDate                   0\n",
      "hitRate                   0\n",
      "dtype: int64\n",
      "The shape of current dataframe: (1428, 21)\n"
     ]
    }
   ],
   "source": [
    "# Step1.1. drop NaN\n",
    "print(\"The shape of original dataframe:\", df_all.shape)\n",
    "\n",
    "# pick only 15 categories\n",
    "# {1:'音樂', 2:'戲劇', 3:'舞蹈', 4:'親子', 5:'獨立音樂', 6:'展覽', 7:'講座', 8:'電影', 11:'綜藝', 13:'競賽', 14:'徵選', 15:'其他', 17:'演唱會', 19:'研習課程', 200:'閱讀'}\n",
    "\n",
    "codes = {1:'music', 2:'theater', 3:'dance', 4:'parent-child', 5:'indie-music', 6:'exhibition', 7:'seminar', 8:'movie', 11:'variety-show', 13:'competition', 14:'audition', 15:'other', 17:'concert', 19:'training', 200:'book-club'}\n",
    "df_all['category']= df_all['category'].apply(lambda x: codes[int(x)] if (int(x) in codes.keys()) else float(\"NaN\"))\n",
    "\n",
    "# check NaN\n",
    "print(df_all.isna().sum())\n",
    "\n",
    "# drop NaN row\n",
    "df_all.dropna(subset = [\"category\"], inplace=True)\n",
    "print(\"The shape of current dataframe:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of original dataframe: (1428, 21)\n",
      "duplicated row number (PK = UID): 59\n",
      "duplicated row number (PK = (UID, category)):  0\n",
      "The shape of current dataframe: (1369, 21)\n"
     ]
    }
   ],
   "source": [
    "# Step1.2. check duplicated data\n",
    "print(\"The shape of original dataframe:\", df_all.shape)\n",
    "print(\"duplicated row number (PK = UID):\", df_all.duplicated(subset=['UID']).sum())\n",
    "print(\"duplicated row number (PK = (UID, category)): \", df_all.duplicated(subset=['UID', 'category']).sum())\n",
    "\n",
    "# create a new table, df_output_category\n",
    "# category = {1:'音樂', 2:'戲劇', 3:'舞蹈', 4:'親子', 5:'獨立音樂', 6:'展覽', 7:'講座', 8:'電影', 11:'綜藝', 13:'競賽', 14:'徵選', 15:'其他', 17:'演唱會', 19:'研習課程', 200:'閱讀'}\n",
    "df_output_category = df_all[['UID', 'category']]\n",
    "\n",
    "# drop duplicated row\n",
    "df_all = df_all.drop_duplicates(subset=['UID'])\n",
    "print(\"The shape of current dataframe:\", df_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of current output dataframe: (1369, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step2.1. \"UID\"\n",
    "\n",
    "# create the second table, df_output\n",
    "df_output = pd.DataFrame(df_all[\"UID\"])\n",
    "print(\"The shape of current output dataframe:\", df_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of current output dataframe: (1369, 3)\n"
     ]
    }
   ],
   "source": [
    "# Step2.2. \"title\", \"descriptionFilterHtml\"\n",
    "column_names = [\"title\", \"descriptionFilterHtml\"]\n",
    "\n",
    "# transform the String data to useful numerical data\n",
    "for column_name in column_names:\n",
    "    new_column_name = column_name+\"Length\"\n",
    "    df_output[new_column_name] = df_all[column_name].apply(lambda x: len(x))\n",
    "print(\"The shape of current output dataframe:\", df_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of current output dataframe: (1369, 4)\n"
     ]
    }
   ],
   "source": [
    "# Step2.3. \"hitRate\"\n",
    "df_output[\"hitRate\"] = pd.DataFrame(df_all[\"hitRate\"])\n",
    "print(\"The shape of current output dataframe:\", df_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2.4. \"showInfo\"\n",
    "df_show = pd.DataFrame()\n",
    "df_output_show = pd.DataFrame()\n",
    "\n",
    "test = df_all[\"showInfo\"]\n",
    "for index, activity in df_all.iterrows():\n",
    "    # create the third table, df_output_show\n",
    "    df_temp = pd.DataFrame(activity[\"showInfo\"])\n",
    "    df_temp['activity_UID'] = pd.Series(activity['UID']).repeat(df_temp.shape[0]).values\n",
    "    df_show = df_show.append(df_temp)\n",
    "    \n",
    "df_output_show['activity_UID'] = df_show['activity_UID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of current output dataframe: (1369, 8)\n"
     ]
    }
   ],
   "source": [
    "# Step2.5. \"showUnit\", \"discountInfo\", \"webSales\", \"sourceWebPromote\"\n",
    "\n",
    "column_names = [\"showUnit\", \"discountInfo\", \"webSales\", \"sourceWebPromote\"]\n",
    "\n",
    "# transform the String data to useful catigorical data with (1, 0) 2 catigories\n",
    "for column_name in column_names:\n",
    "    df_output[column_name] = df_all[column_name].apply(lambda x: 0 if x==\"\" else 1)\n",
    "print(\"The shape of current output dataframe:\", df_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of current output dataframe: (1369, 12)\n"
     ]
    }
   ],
   "source": [
    "# Step2.6. \"masterUnit\", \"subUnit\", \"supportUnit\", \"otherUnit\"\n",
    "column_names = [\"masterUnit\", \"subUnit\", \"supportUnit\", \"otherUnit\"]\n",
    "\n",
    "# transform the String data to useful numerical data\n",
    "for column_name in column_names:\n",
    "    new_column_name = column_name+\"Num\"\n",
    "    df_output[new_column_name] = df_all[column_name].apply(lambda x: 0 if len(x)==0 else len(x))\n",
    "\n",
    "print(\"The shape of current output dataframe:\", df_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of final output dataframe: (1369, 13)\n"
     ]
    }
   ],
   "source": [
    "# Step2.7. \"startDate\", \"endDate\" tobe: error year\n",
    "# transform start and end date to a single column, duration, a numerical data\n",
    "date_format = \"%Y/%m/%d\"\n",
    "\n",
    "start = df_all[\"startDate\"].apply(lambda x: datetime.strptime(x, date_format))\n",
    "end = df_all[\"endDate\"].apply(lambda x: datetime.strptime(x, date_format))\n",
    "duration = end - start\n",
    "df_output[\"duration\"] = duration.apply(lambda x: x.days+1)\n",
    "\n",
    "# create a new table, df_output_date TOBE\n",
    "\n",
    "print(\"The shape of final output dataframe:\", df_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## column by column inside \"showInfo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2.8. \"location\" in \"showInfo\" (continue from Step2.4.)\n",
    "\n",
    "county_names = [\"臺北市\", \"新北市\", \"桃園市\", \"臺中市\", \"臺南市\", \"高雄市\", \"新竹縣\", \"苗栗縣\", \"彰化縣\", \"南投縣\", \"雲林縣\", \"嘉義縣\", \"屏東縣\", \"宜蘭縣\", \"花蓮縣\", \"臺東縣\", \"澎湖縣\", \"金門縣\", \"連江縣\", \"基隆市\", \"新竹市\", \"嘉義市\"]\n",
    "\n",
    "# transform location to useful String data\n",
    "df_output_show['county'] = df_show['location']\n",
    "for county_name in county_names:\n",
    "    df_output_show['county'] = df_output_show['county'].apply(lambda x: county_name if county_name in x else x)\n",
    "df_output_show['county'] = df_output_show['county'].apply(lambda x: \"\" if x not in county_names else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2.9. \"locationName\" in \"showInfo\" (continue from Step2.4.)\n",
    "df_output_show['online'] = df_show['locationName']\n",
    "\n",
    "# transform the String data to useful catigorical data\n",
    "df_output_show['online'] = df_output_show['online'].apply(lambda x: 1 if \"線上\" in x else 0)\n",
    "\n",
    "# todo: no county and not online~?\n",
    "# df_output_show['online'] = df_output_show.apply(lambda x: 2 if x['county']==\"\" else x['online'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2.10. \"onSales\"\n",
    "# transform String to int catigorical data\n",
    "df_output_show['onSales'] = df_show['onSales'].apply(lambda x: 1 if x==\"Y\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2.11. \"price\"\n",
    "df_output_show['priceByAge'] = df_show['price'].apply(lambda x: 1 if \"歲\" in x else 0)\n",
    "df_output_show['priceFree'] = df_show['price'].apply(lambda x: 1 if \"免費\" in x or x==\"\" else 0)\n",
    "\n",
    "# # TOBE: parse the pricing rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID                            0\n",
      "titleLength                    0\n",
      "descriptionFilterHtmlLength    0\n",
      "hitRate                        0\n",
      "showUnit                       0\n",
      "discountInfo                   0\n",
      "webSales                       0\n",
      "sourceWebPromote               0\n",
      "masterUnitNum                  0\n",
      "subUnitNum                     0\n",
      "supportUnitNum                 0\n",
      "otherUnitNum                   0\n",
      "duration                       0\n",
      "online                         0\n",
      "onSales                        0\n",
      "priceByAge                     0\n",
      "priceFree                      0\n",
      "county                         0\n",
      "showNum                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step2.12. transform the \"showInfo\" into activity\n",
    "df_temp = df_output_show.groupby('activity_UID')\n",
    "df_as_group = df_temp[['online', 'onSales', 'priceByAge', 'priceFree']].sum()\n",
    "\n",
    "df_as_group = pd.merge(df_as_group, df_temp[['county']].nunique(),\n",
    "                       left_on='activity_UID', right_on='activity_UID')\n",
    "df_as_group = df_as_group.assign(showNum = df_output_show.groupby('activity_UID').size())\n",
    "\n",
    "df_output = pd.merge(df_output, df_as_group, \n",
    "                     left_on='UID', right_on='activity_UID')\n",
    "print(df_output.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From DataFrame to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step3.1\n",
    "# connect to PostgrSQL db\n",
    " \n",
    "# establish connections\n",
    "conn_string = 'postgresql://postgres:00000000@127.0.0.1/postgres'\n",
    "db = create_engine(conn_string)\n",
    "conn = db.connect()\n",
    "conn1 = psycopg2.connect(\n",
    "  database=\"postgres\",\n",
    "  user='postgres', \n",
    "  password='00000000', \n",
    "  host='127.0.0.1', \n",
    "  port= '5432'\n",
    ")\n",
    "  \n",
    "conn1.autocommit = True\n",
    "\n",
    "# cur will be used to run the query\n",
    "cur = conn1.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_staging_table_(cursor, sql):\n",
    "    cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn(df,table,cur):\n",
    "\n",
    "    if len(df) > 0:\n",
    "        df_columns = list(df)\n",
    "        # create (col1,col2,...)\n",
    "        columns = \",\".join(df_columns)\n",
    "\n",
    "        # create VALUES('%s', '%s\",...) one '%s' per column\n",
    "        values = \"VALUES({})\".format(\",\".join([\"%s\" for _ in df_columns])) \n",
    "\n",
    "        #create INSERT INTO table (columns) VALUES('%s',...)\n",
    "        insert_stmt = \"INSERT INTO {} ({}) {}\".format(table,columns,values)\n",
    "        cur.execute(\"truncate \" + table + \";\")  # avoiding uploading duplicate data!\n",
    "        cur = conn1.cursor()\n",
    "        psycopg2.extras.execute_batch(cur, insert_stmt, df.values)\n",
    "    conn1.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the first table: activities\n",
    "sql_a = \"\"\"\n",
    "    DROP TABLE IF EXISTS activityDB;\n",
    "    CREATE UNLOGGED TABLE activityDB (\n",
    "        UID                         TEXT PRIMARY KEY,\n",
    "        titleLength                 INT,\n",
    "        descriptionFilterHtmlLength INT,\n",
    "        hitRate                     INT,\n",
    "        showUnit                    INT,\n",
    "        discountInfo                INT,\n",
    "        webSales                    INT,\n",
    "        sourceWebPromote            INT,\n",
    "        masterUnitNum               INT,\n",
    "        subUnitNum                  INT,\n",
    "        supportUnitNum              INT,\n",
    "        otherUnitNum                INT,\n",
    "        duration                    INT,\n",
    "        online                      INT,\n",
    "        onSales                     INT,\n",
    "        priceByAge                  INT,\n",
    "        priceFree                   INT,\n",
    "        county                      INT,\n",
    "        showNum                     INT\n",
    ");\"\"\"\n",
    "# sending the table to psql\n",
    "with conn1.cursor() as cursor:\n",
    "    create_staging_table_(cursor, sql_a)\n",
    "\n",
    "# Convert Df to List(Dict()) : then sending from Python to PSQL\n",
    "fcn(df_output,'activityDB',cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ForeignKeyViolation",
     "evalue": "insert or update on table \"categorydb\" violates foreign key constraint \"categorydb_uid_fkey\"\nDETAIL:  Key (uid)=(62580030d083a31fec0aef4d) is not present in table \"activitydb\".\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForeignKeyViolation\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a445ffdf1be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Convert Df to List(Dict()) : then sending from Python to PSQL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mfcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_output_category\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categoryDB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-122bcb2aca69>\u001b[0m in \u001b[0;36mfcn\u001b[0;34m(df, table, cur)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"truncate \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# avoiding uploading duplicate data!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_stmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mconn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/psycopg2/extras.py\u001b[0m in \u001b[0;36mexecute_batch\u001b[0;34m(cur, sql, argslist, page_size)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_paginate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margslist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0msqls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mForeignKeyViolation\u001b[0m: insert or update on table \"categorydb\" violates foreign key constraint \"categorydb_uid_fkey\"\nDETAIL:  Key (uid)=(62580030d083a31fec0aef4d) is not present in table \"activitydb\".\n"
     ]
    }
   ],
   "source": [
    "# creating the second table: catigories\n",
    "sql_c = \"\"\"\n",
    "    DROP TABLE IF EXISTS categoryDB;\n",
    "    CREATE UNLOGGED TABLE categoryDB (\n",
    "        UID                         TEXT,\n",
    "        category                    TEXT,\n",
    "        PRIMARY KEY (UID, category),\n",
    "        FOREIGN KEY (UID)\n",
    "            REFERENCES activityDB (UID)\n",
    ");\"\"\"\n",
    "# sending the table to psql\n",
    "with conn1.cursor() as cursor:\n",
    "    create_staging_table_(cursor, sql_c)\n",
    "\n",
    "# Convert Df to List(Dict()) : then sending from Python to PSQL\n",
    "fcn(df_output_category,'categoryDB',cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the third table: shows\n",
    "sql_s = \"\"\"\n",
    "    DROP TABLE IF EXISTS showDB;\n",
    "    CREATE UNLOGGED TABLE showDB (\n",
    "        show_id         serial PRIMARY KEY,\n",
    "        activity_UID    TEXT,\n",
    "        county          TEXT,\n",
    "        online          INT,\n",
    "        onSales         INT,\n",
    "        priceByAge      INT,\n",
    "        priceFree       INT,\n",
    "        FOREIGN KEY (activity_UID)\n",
    "            REFERENCES activityDB (UID)\n",
    "\n",
    ");\"\"\"\n",
    "# sending the table to psql\n",
    "with conn1.cursor() as cursor:\n",
    "    create_staging_table_(cursor, sql_s)\n",
    "\n",
    "# Convert Df to List(Dict()) : then sending from Python to PSQL\n",
    "fcn(df_output_show,'showDB',cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
